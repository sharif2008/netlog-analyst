{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b1beef3",
   "metadata": {},
   "source": [
    "# Digital Forensics NIDS (CIC-IDS-2017)\n",
    "This notebook trains multiple ML models for **binary intrusion detection** (BENIGN vs ATTACK) using CIC-IDS-2017 flow features, performs **scaling + RFE feature selection**, evaluates models, and exports the **best models** plus **metadata** for reproducible inference.\n",
    "\n",
    "**What you need:** one or more CIC-IDS-2017 CSV files (e.g., from CICFlowMeter). Set `DATA_FILES` below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d94774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 0) Imports & Settings\n",
    "# =========================\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 52\n",
    "SAMPLE_FRAC = 0.10          # set to 1.0 to use full data (may be heavy)\n",
    "RFE_TOP_K = 30              # number of features to select\n",
    "TEST_SIZE = 0.25\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_colwidth\", 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067fd3fa",
   "metadata": {},
   "source": [
    "## 1) Load CIC-IDS-2017 CSVs\n",
    "Set `DATA_FILES` to your CSV paths. If you have a folder, you can glob it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2911285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 1) Data Paths (EDIT ME)\n",
    "# =========================\n",
    "\n",
    "# Option A: explicit list of CSVs\n",
    "DATA_FILES = [\n",
    "    # r\"C:\\path\\to\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "    # r\"C:\\path\\to\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "]\n",
    "\n",
    "# Option B: glob a directory (uncomment and set)\n",
    "# import glob\n",
    "# DATA_DIR = r\"C:\\path\\to\\CICIDS2017\"\n",
    "# DATA_FILES = sorted(glob.glob(os.path.join(DATA_DIR, \"*.csv\")))\n",
    "\n",
    "assert len(DATA_FILES) > 0, \"Please set DATA_FILES to at least one CSV path.\"\n",
    "\n",
    "print(\"CSV files:\")\n",
    "for f in DATA_FILES:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5ca38",
   "metadata": {},
   "source": [
    "### 1.1 Read and align common columns\n",
    "CIC-IDS CSV files sometimes differ slightly in columns. We take the **intersection** of columns across files and concatenate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfc409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read each file\n",
    "dfs = []\n",
    "col_sets = []\n",
    "\n",
    "for f in DATA_FILES:\n",
    "    df_i = pd.read_csv(f)\n",
    "    dfs.append(df_i)\n",
    "    col_sets.append(set(df_i.columns))\n",
    "\n",
    "common_cols = sorted(list(set.intersection(*col_sets)))\n",
    "print(\"Common columns across files:\", len(common_cols))\n",
    "\n",
    "df_full = pd.concat([d[common_cols] for d in dfs], ignore_index=True)\n",
    "print(\"Merged shape:\", df_full.shape)\n",
    "\n",
    "df_full.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71682cd6",
   "metadata": {},
   "source": [
    "## 2) Cleaning + Sampling\n",
    "We normalize column names, replace +/-inf with NaN, drop NaNs, drop duplicates, then sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_full.columns = df_full.columns.str.strip()\n",
    "\n",
    "# Replace +/-inf -> NaN\n",
    "df_full = df_full.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop rows with NaN\n",
    "before = len(df_full)\n",
    "df_full = df_full.dropna()\n",
    "after = len(df_full)\n",
    "print(f\"Dropped NaNs: {before-after:,} rows\")\n",
    "\n",
    "# Drop duplicates\n",
    "before = len(df_full)\n",
    "df_full = df_full.drop_duplicates()\n",
    "after = len(df_full)\n",
    "print(f\"Dropped duplicates: {before-after:,} rows\")\n",
    "\n",
    "# Optional sampling to speed up experiments\n",
    "if SAMPLE_FRAC < 1.0:\n",
    "    df = df_full.sample(frac=SAMPLE_FRAC, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "else:\n",
    "    df = df_full.reset_index(drop=True)\n",
    "\n",
    "print(\"Working df shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338a5ae",
   "metadata": {},
   "source": [
    "## 3) Create binary label `Attack_Binary`\n",
    "Assumes CIC-IDS uses `Label` column where BENIGN indicates normal traffic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efc33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert \"Label\" in df.columns, \"Expected a 'Label' column in your CIC-IDS CSV.\"\n",
    "\n",
    "# Normalize label text\n",
    "df[\"Label\"] = df[\"Label\"].astype(str).str.strip()\n",
    "\n",
    "# Binary label: 0=BENIGN, 1=ATTACK\n",
    "df[\"Attack_Binary\"] = np.where(df[\"Label\"].str.upper() == \"BENIGN\", 0, 1)\n",
    "\n",
    "print(df[\"Attack_Binary\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795abfe2",
   "metadata": {},
   "source": [
    "## 4) Select base features\n",
    "**Base features** = all usable feature columns (after cleaning) excluding labels/targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop obvious non-features if present (depends on your dataset)\n",
    "NON_FEATURES = {\"Label\", \"Attack_Binary\"}\n",
    "\n",
    "X_base = df.drop(columns=[c for c in NON_FEATURES if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "# Keep only numeric columns\n",
    "X_base = X_base.select_dtypes(include=[np.number])\n",
    "\n",
    "y = df[\"Attack_Binary\"].astype(int).values\n",
    "\n",
    "base_features = X_base.columns.tolist()\n",
    "print(\"Base feature count:\", len(base_features))\n",
    "print(\"First 20 base features:\", base_features[:20])\n",
    "\n",
    "X_base.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d386c2ab",
   "metadata": {},
   "source": [
    "## 5) (Optional) Correlation filtering\n",
    "This is optional. If you already did correlation filtering in your original notebook, keep it here.\n",
    "\n",
    "We remove one of any pair of features with absolute correlation above `CORR_THRESH`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CORR_FILTER = True\n",
    "CORR_THRESH = 0.95\n",
    "\n",
    "X_corr = X_base.copy()\n",
    "filtered_features = base_features.copy()\n",
    "\n",
    "if CORR_FILTER and X_corr.shape[1] > 1:\n",
    "    corr = X_corr.corr().abs()\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > CORR_THRESH)]\n",
    "    print(\"Correlation-based drop count:\", len(to_drop))\n",
    "\n",
    "    X_base_f = X_corr.drop(columns=to_drop)\n",
    "    filtered_features = X_base_f.columns.tolist()\n",
    "else:\n",
    "    X_base_f = X_corr\n",
    "\n",
    "print(\"Filtered feature count:\", len(filtered_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28630a4",
   "metadata": {},
   "source": [
    "## 6) Train/test split + scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77c0ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_base_f, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "print(\"Train shape:\", X_train_scaled.shape, \"Test shape:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2b8b2",
   "metadata": {},
   "source": [
    "## 7) RFE Feature Selection (RandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_for_rfe = RandomForestClassifier(n_estimators=150, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "rfe = RFE(estimator=rf_for_rfe, n_features_to_select=RFE_TOP_K, step=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "selected_mask = rfe.support_\n",
    "selected_features = [f for f, m in zip(filtered_features, selected_mask) if m]\n",
    "\n",
    "print(\"Selected features:\", len(selected_features))\n",
    "print(selected_features)\n",
    "\n",
    "# Apply mask to scaled arrays\n",
    "X_train_sel = X_train_scaled[:, selected_mask]\n",
    "X_test_sel  = X_test_scaled[:, selected_mask]\n",
    "\n",
    "assert X_train_sel.shape[1] == len(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e2ae94",
   "metadata": {},
   "source": [
    "## 8) Train and evaluate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=2000, n_jobs=-1),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=False, random_state=RANDOM_STATE),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Optional: XGBoost/LightGBM/CatBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    models[\"XGBoost\"] = XGBClassifier(\n",
    "        n_estimators=400, learning_rate=0.1, max_depth=6,\n",
    "        subsample=0.8, colsample_bytree=0.8, reg_lambda=1.0,\n",
    "        random_state=RANDOM_STATE, n_jobs=-1, eval_metric=\"logloss\"\n",
    "    )\n",
    "    print(\"✅ XGBoost available\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ XGBoost not available:\", str(e)[:120])\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    models[\"LightGBM\"] = LGBMClassifier(\n",
    "        n_estimators=500, learning_rate=0.05, random_state=RANDOM_STATE, n_jobs=-1\n",
    "    )\n",
    "    print(\"✅ LightGBM available\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ LightGBM not available:\", str(e)[:120])\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    models[\"CatBoost\"] = CatBoostClassifier(\n",
    "        iterations=600, learning_rate=0.05, depth=8,\n",
    "        random_seed=RANDOM_STATE, verbose=False\n",
    "    )\n",
    "    print(\"✅ CatBoost available\")\n",
    "except Exception as e:\n",
    "    print(\"ℹ️ CatBoost not available:\", str(e)[:120])\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    y_pred = model.predict(X_test_sel)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    results[name] = {\n",
    "        \"Accuracy (%)\": acc * 100,\n",
    "        \"Precision (%)\": prec * 100,\n",
    "        \"Recall (%)\": rec * 100,\n",
    "        \"F1-Score (%)\": f1 * 100\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "results_df = results_df.sort_values(by=\"Accuracy (%)\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Model Comparison (Test Set) ===\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed513414",
   "metadata": {},
   "source": [
    "### 8.1 Plot: accuracy by model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6524008",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(results_df[\"Model\"], results_df[\"Accuracy (%)\"])\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Model Accuracy (Test Set)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe672a7",
   "metadata": {},
   "source": [
    "## 9) Pick top-2 models and export\n",
    "We export the top-2 models (by accuracy) and the metadata required for inference: base feature order, correlation-filtered features, scaler, RFE mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a63dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top2 = results_df.head(2)[\"Model\"].tolist()\n",
    "print(\"Top 2 models:\", top2)\n",
    "\n",
    "best_name = top2[0]\n",
    "second_name = top2[1] if len(top2) > 1 else None\n",
    "\n",
    "best_model = models[best_name]\n",
    "second_model = models[second_name] if second_name else None\n",
    "\n",
    "# Refit best/second on full selected training data (train split only) already fit above; keep as-is.\n",
    "# You may optionally refit on combined train+test if you won't evaluate anymore.\n",
    "\n",
    "# Export models\n",
    "joblib.dump(best_model, f\"best_model_{best_name}.pkl\")\n",
    "if second_model is not None:\n",
    "    joblib.dump(second_model, f\"second_model_{second_name}.pkl\")\n",
    "\n",
    "# Export metadata (single file)\n",
    "metadata = {\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"sample_frac\": SAMPLE_FRAC,\n",
    "    \"corr_filter\": CORR_FILTER,\n",
    "    \"corr_thresh\": CORR_THRESH,\n",
    "    \"test_size\": TEST_SIZE,\n",
    "    \"rfe_top_k\": int(selected_mask.sum()),\n",
    "    \"base_features\": base_features,                 # before corr filter\n",
    "    \"filtered_features\": filtered_features,         # after corr filter (and numeric-only)\n",
    "    \"selected_mask\": selected_mask,                 # aligns with filtered_features\n",
    "    \"selected_features\": selected_features,\n",
    "    \"scaler\": scaler\n",
    "}\n",
    "joblib.dump(metadata, \"nids_feature_metadata.pkl\")\n",
    "\n",
    "print(\"✅ Exported:\")\n",
    "print(\" -\", f\"best_model_{best_name}.pkl\")\n",
    "if second_model is not None:\n",
    "    print(\" -\", f\"second_model_{second_name}.pkl\")\n",
    "print(\" - nids_feature_metadata.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21d4be",
   "metadata": {},
   "source": [
    "## 10) Inference demo on a single CSV row\n",
    "This shows how to load the model/metadata and run prediction on a new CSV. It also prevents the common **missing base feature** error by adding missing columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da877b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Load what we exported =====\n",
    "meta = joblib.load(\"nids_feature_metadata.pkl\")\n",
    "model_path = f\"best_model_{best_name}.pkl\"\n",
    "model_loaded = joblib.load(model_path)\n",
    "\n",
    "def prepare_features_for_inference(df_in: pd.DataFrame, meta: dict) -> np.ndarray:\n",
    "    df_in = df_in.copy()\n",
    "    df_in.columns = df_in.columns.str.strip()\n",
    "\n",
    "    # Keep only numeric columns that were in training base_features\n",
    "    # If your inference CSV contains extra columns, we ignore them.\n",
    "    # Add missing columns (filled with 0)\n",
    "    for c in meta[\"filtered_features\"]:\n",
    "        if c not in df_in.columns:\n",
    "            df_in[c] = 0\n",
    "\n",
    "    X_base_inf = df_in[meta[\"filtered_features\"]].select_dtypes(include=[np.number])\n",
    "\n",
    "    # Scale\n",
    "    X_scaled_inf = meta[\"scaler\"].transform(X_base_inf)\n",
    "\n",
    "    # Apply RFE mask (aligned with filtered_features)\n",
    "    X_sel_inf = X_scaled_inf[:, meta[\"selected_mask\"]]\n",
    "    return X_sel_inf\n",
    "\n",
    "# --- Create a sample 1-row dataframe using training means (safe demo) ---\n",
    "sample_row = X_base_f.mean(numeric_only=True).to_dict()\n",
    "df_sample = pd.DataFrame([sample_row])\n",
    "\n",
    "X_inf = prepare_features_for_inference(df_sample, meta)\n",
    "pred = model_loaded.predict(X_inf)[0]\n",
    "print(\"Prediction on sample row:\", \"ATTACK\" if int(pred)==1 else \"BENIGN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6abd4",
   "metadata": {},
   "source": [
    "## 11) Export an inference CSV template\n",
    "Use this template to ensure your future CSV has the correct headers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(columns=filtered_features).to_csv(\"inference_template.csv\", index=False)\n",
    "print(\"✅ Wrote inference_template.csv with\", len(filtered_features), \"columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bedff3",
   "metadata": {},
   "source": [
    "## 12) (Optional) RandomForest feature importance on selected features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed34170",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"RandomForest\" in models:\n",
    "    rf_final = models[\"RandomForest\"]\n",
    "    if hasattr(rf_final, \"feature_importances_\") and len(rf_final.feature_importances_) == len(selected_features):\n",
    "        fi_df = (pd.DataFrame({\"Feature\": selected_features, \"Importance\": rf_final.feature_importances_})\n",
    "                 .sort_values(\"Importance\", ascending=False)\n",
    "                 .reset_index(drop=True))\n",
    "        fi_df.head(20)\n",
    "    else:\n",
    "        print(\"RandomForest not fitted yet or feature_importances_ mismatch.\")\n",
    "else:\n",
    "    print(\"RandomForest not in models.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
