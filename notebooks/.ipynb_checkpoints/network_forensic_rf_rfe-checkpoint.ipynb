{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38c45a7",
   "metadata": {},
   "source": [
    "# Network Forensic Analysis Tool on CIC-IDS-2017  \n",
    "### Random Forest + RFE (Top 30 Features, No Redundancy / Multicollinearity)\n",
    "\n",
    "This notebook builds a **forensic-style network log analysis tool** using the **CIC-IDS-2017** dataset:\n",
    "\n",
    "- Loads and merges multiple CIC-IDS-2017 CSV files (Monday, Wednesday, Friday PortScan, Friday DDoS)\n",
    "- Cleans the data (NaNs, infinities, constant columns)\n",
    "- Creates a binary label: **0 = BENIGN, 1 = ATTACK**\n",
    "- Removes **highly correlated (multicollinear) features**\n",
    "- Uses **Recursive Feature Elimination (RFE)** with **RandomForest** to select the **top 30 features**\n",
    "- Trains a final **RandomForest** model on these 30 features\n",
    "- Evaluates the model (accuracy, classification report, confusion matrix)\n",
    "- Picks **one random flow** and predicts whether it is **BENIGN** or **ATTACK** (for forensic triage).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f64655",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a665e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4b2e3",
   "metadata": {},
   "source": [
    "## 2. Load and Merge CIC-IDS-2017 CSV Files\n",
    "\n",
    "We use four commonly used CIC-IDS-2017 files:\n",
    "\n",
    "- Monday-WorkingHours.pcap_ISCX.csv (mostly BENIGN)\n",
    "- Wednesday-workingHours.pcap_ISCX.csv (mixed traffic)\n",
    "- Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
    "- Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
    "\n",
    "Update the paths below if your files are in a different folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1354fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/Monday-WorkingHours.pcap_ISCX.csv',\n",
       " '../data/Wednesday-workingHours.pcap_ISCX.csv',\n",
       " '../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
       " '../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of CIC-IDS-2017 CSV files (update paths if needed)\n",
    "files = [\n",
    "    \"../data/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "    \"../data/Wednesday-workingHours.pcap_ISCX.csv\",\n",
    "    \"../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "    \"../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c60d0af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../data/Monday-WorkingHours.pcap_ISCX.csv\n",
      "  Shape: (529918, 79)\n",
      "Loading: ../data/Wednesday-workingHours.pcap_ISCX.csv\n",
      "  Shape: (692703, 79)\n",
      "Loading: ../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "  Shape: (286467, 79)\n",
      "Loading: ../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "  Shape: (225745, 79)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_cic_file(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load a CIC-IDS-2017 CSV and normalize column names.\"\"\"\n",
    "    print(f\"Loading: {path}\")\n",
    "    df_tmp = pd.read_csv(path)\n",
    "    df_tmp.columns = df_tmp.columns.str.strip()\n",
    "    print(\"  Shape:\", df_tmp.shape)\n",
    "    return df_tmp\n",
    "\n",
    "dfs = [load_cic_file(f) for f in files]\n",
    "\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9228661",
   "metadata": {},
   "source": [
    "## 3. Align Columns and Concatenate\n",
    "\n",
    "We keep only the columns that are common across all files, including the **Label** column, and then merge them into a single dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e3cfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common columns: 79\n",
      "Sample common columns: ['ACK Flag Count', 'Active Max', 'Active Mean', 'Active Min', 'Active Std', 'Average Packet Size', 'Avg Bwd Segment Size', 'Avg Fwd Segment Size', 'Bwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Header Length', 'Bwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Min', 'Bwd IAT Std', 'Bwd IAT Total', 'Bwd PSH Flags', 'Bwd Packet Length Max', 'Bwd Packet Length Mean']\n",
      "Merged shape: (1734833, 79)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Bwd Avg Bulk Rate</th>\n",
       "      <th>Bwd Avg Bytes/Bulk</th>\n",
       "      <th>...</th>\n",
       "      <th>Subflow Bwd Packets</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601501</th>\n",
       "      <td>0</td>\n",
       "      <td>7005579</td>\n",
       "      <td>7005579.0</td>\n",
       "      <td>7005579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281978</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACK Flag Count  Active Max  Active Mean  Active Min  Active Std  \\\n",
       "1159211               0           0          0.0           0         0.0   \n",
       "601501                0     7005579    7005579.0     7005579         0.0   \n",
       "1383497               0           0          0.0           0         0.0   \n",
       "1281978               1           0          0.0           0         0.0   \n",
       "1396436               0           0          0.0           0         0.0   \n",
       "\n",
       "         Average Packet Size  Avg Bwd Segment Size  Avg Fwd Segment Size  \\\n",
       "1159211            60.000000                  72.0                  32.0   \n",
       "601501              0.000000                   0.0                   0.0   \n",
       "1383497             3.000000                   6.0                   0.0   \n",
       "1281978            37.833333                  46.0                  27.0   \n",
       "1396436             3.000000                   6.0                   0.0   \n",
       "\n",
       "         Bwd Avg Bulk Rate  Bwd Avg Bytes/Bulk  ...  Subflow Bwd Packets  \\\n",
       "1159211                  0                   0  ...                    2   \n",
       "601501                   0                   0  ...                    0   \n",
       "1383497                  0                   0  ...                    1   \n",
       "1281978                  0                   0  ...                    1   \n",
       "1396436                  0                   0  ...                    1   \n",
       "\n",
       "         Subflow Fwd Bytes  Subflow Fwd Packets  Total Backward Packets  \\\n",
       "1159211                 64                    2                       2   \n",
       "601501                   0                    7                       0   \n",
       "1383497                  0                    1                       1   \n",
       "1281978                135                    5                       1   \n",
       "1396436                  0                    1                       1   \n",
       "\n",
       "         Total Fwd Packets  Total Length of Bwd Packets  \\\n",
       "1159211                  2                          144   \n",
       "601501                   7                            0   \n",
       "1383497                  1                            6   \n",
       "1281978                  5                           46   \n",
       "1396436                  1                            6   \n",
       "\n",
       "         Total Length of Fwd Packets  URG Flag Count  act_data_pkt_fwd  \\\n",
       "1159211                           64               0                 1   \n",
       "601501                             0               0                 0   \n",
       "1383497                            0               0                 0   \n",
       "1281978                          135               0                 4   \n",
       "1396436                            0               0                 0   \n",
       "\n",
       "         min_seg_size_forward  \n",
       "1159211                    20  \n",
       "601501                     40  \n",
       "1383497                    40  \n",
       "1281978                    20  \n",
       "1396436                    40  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find common columns across all dataframes\n",
    "common_cols = set(dfs[0].columns)\n",
    "for d in dfs[1:]:\n",
    "    common_cols = common_cols.intersection(set(d.columns))\n",
    "\n",
    "common_cols = sorted(list(common_cols))\n",
    "print(\"Number of common columns:\", len(common_cols))\n",
    "print(\"Sample common columns:\", common_cols[:20])\n",
    "\n",
    "# Keep only common columns and concatenate\n",
    "dfs_common = [d[common_cols].copy() for d in dfs]\n",
    "df_full = pd.concat(dfs_common, axis=0, ignore_index=True)\n",
    "print(\"Merged shape:\", df_full.shape)\n",
    "\n",
    "# Get 10% of the original dataset\n",
    "df_full=df_full.sample(frac=0.10, random_state=52)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a5846",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning and Binary Label Creation\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Drop fully empty columns.  \n",
    "2. Replace infinities with NaN and drop rows with NaN.  \n",
    "3. Normalize the `Label` text.  \n",
    "4. Create a binary label `Attack_Binary`:  \n",
    "   - `0` → BENIGN  \n",
    "   - `1` → any attack label (DDoS, PortScan, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36a957e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning shape: (173255, 80)\n",
      "Binary label counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Attack_Binary\n",
       "0    119627\n",
       "1     53628\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_full.copy()\n",
    "\n",
    "# Drop fully empty columns\n",
    "df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Replace infinities and drop NaNs\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalize Label text\n",
    "df[\"Label\"] = df[\"Label\"].astype(str).str.strip()\n",
    "\n",
    "# Binary label mapping\n",
    "def map_attack_binary(label: str) -> int:\n",
    "    label = label.upper()\n",
    "    if \"BENIGN\" in label:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df[\"Attack_Binary\"] = df[\"Label\"].apply(map_attack_binary)\n",
    "\n",
    "print(\"After cleaning shape:\", df.shape)\n",
    "print(\"Binary label counts:\")\n",
    "df[\"Attack_Binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f5522",
   "metadata": {},
   "source": [
    "## 5. Keep Only Numeric, Non-Constant Features\n",
    "\n",
    "We keep only numeric columns and remove any feature that has the same value for all rows (constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3da504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric non-constant columns (including label): 69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Bwd Segment Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Bwd Header Length</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>...</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>Subflow Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Attack_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>72.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601501</th>\n",
       "      <td>0</td>\n",
       "      <td>7005579</td>\n",
       "      <td>7005579.0</td>\n",
       "      <td>7005579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281978</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>46.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>135</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACK Flag Count  Active Max  Active Mean  Active Min  Active Std  \\\n",
       "1159211               0           0          0.0           0         0.0   \n",
       "601501                0     7005579    7005579.0     7005579         0.0   \n",
       "1383497               0           0          0.0           0         0.0   \n",
       "1281978               1           0          0.0           0         0.0   \n",
       "1396436               0           0          0.0           0         0.0   \n",
       "\n",
       "         Average Packet Size  Avg Bwd Segment Size  Avg Fwd Segment Size  \\\n",
       "1159211            60.000000                  72.0                  32.0   \n",
       "601501              0.000000                   0.0                   0.0   \n",
       "1383497             3.000000                   6.0                   0.0   \n",
       "1281978            37.833333                  46.0                  27.0   \n",
       "1396436             3.000000                   6.0                   0.0   \n",
       "\n",
       "         Bwd Header Length  Bwd IAT Max  ...  Subflow Fwd Bytes  \\\n",
       "1159211                 40            4  ...                 64   \n",
       "601501                   0            0  ...                  0   \n",
       "1383497                 20            0  ...                  0   \n",
       "1281978                 20            0  ...                135   \n",
       "1396436                 20            0  ...                  0   \n",
       "\n",
       "         Subflow Fwd Packets  Total Backward Packets  Total Fwd Packets  \\\n",
       "1159211                    2                       2                  2   \n",
       "601501                     7                       0                  7   \n",
       "1383497                    1                       1                  1   \n",
       "1281978                    5                       1                  5   \n",
       "1396436                    1                       1                  1   \n",
       "\n",
       "         Total Length of Bwd Packets  Total Length of Fwd Packets  \\\n",
       "1159211                          144                           64   \n",
       "601501                             0                            0   \n",
       "1383497                            6                            0   \n",
       "1281978                           46                          135   \n",
       "1396436                            6                            0   \n",
       "\n",
       "         URG Flag Count  act_data_pkt_fwd  min_seg_size_forward  Attack_Binary  \n",
       "1159211               0                 1                    20              0  \n",
       "601501                0                 0                    40              1  \n",
       "1383497               0                 0                    40              1  \n",
       "1281978               0                 4                    20              0  \n",
       "1396436               0                 0                    40              1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Remove constant columns\n",
    "numeric_nonconst = [c for c in numeric_cols if df[c].nunique() > 1]\n",
    "\n",
    "# Ensure Attack_Binary is included\n",
    "if \"Attack_Binary\" not in numeric_nonconst:\n",
    "    numeric_nonconst.append(\"Attack_Binary\")\n",
    "\n",
    "df_num = df[numeric_nonconst].copy()\n",
    "print(\"Numeric non-constant columns (including label):\", len(numeric_nonconst))\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30990283",
   "metadata": {},
   "source": [
    "## 6. Remove Multicollinearity (Highly Correlated Features)\n",
    "\n",
    "To avoid redundancy and multicollinearity, we:\n",
    "\n",
    "- Compute a correlation matrix between features.  \n",
    "- Drop one of each pair of features whose absolute correlation is **> 0.90**.\n",
    "\n",
    "This keeps the feature set more compact and reduces overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10dcbafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping due to multicollinearity: 33 features\n",
      "Features remaining after multicollinearity removal: 35\n"
     ]
    }
   ],
   "source": [
    "feature_cols_base = [c for c in df_num.columns if c != \"Attack_Binary\"]\n",
    "\n",
    "corr_matrix = df_num[feature_cols_base].corr().abs()\n",
    "\n",
    "# Upper triangle of the correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Features to drop\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > 0.90)]\n",
    "\n",
    "print(\"Dropping due to multicollinearity:\", len(to_drop), \"features\")\n",
    "\n",
    "df_base = df_num.drop(columns=to_drop)\n",
    "base_features = [c for c in df_base.columns if c != \"Attack_Binary\"]\n",
    "print(\"Features remaining after multicollinearity removal:\", len(base_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb04d0",
   "metadata": {},
   "source": [
    "## 7. Train/Test Split\n",
    "\n",
    "We now split the cleaned, deduplicated features into training and test sets.\n",
    "\n",
    "- 70% for training  \n",
    "- 30% for testing  \n",
    "- Stratified by `Attack_Binary` to preserve class balance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa4e5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (121278, 35)\n",
      "Test shape: (51977, 35)\n"
     ]
    }
   ],
   "source": [
    "X_base = df_base[base_features].values\n",
    "y = df_base[\"Attack_Binary\"].values\n",
    "\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "    X_base, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train_base.shape)\n",
    "print(\"Test shape:\", X_test_base.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3271925e",
   "metadata": {},
   "source": [
    "## 8. Feature Selection with RFE (Top 30 Features)\n",
    "\n",
    "We use **Recursive Feature Elimination (RFE)** with a **RandomForest** estimator to select the **Top 30 most important features**:\n",
    "\n",
    "- RFE repeatedly fits the model and removes the least important features.  \n",
    "- We keep at most 30 features (or fewer if there are less than 30 available after cleaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b836f447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected TOP 20 features via RFE:\n",
      "- Average Packet Size\n",
      "- Avg Fwd Segment Size\n",
      "- Bwd Header Length\n",
      "- Bwd Packet Length Min\n",
      "- Bwd Packets/s\n",
      "- Destination Port\n",
      "- Flow Bytes/s\n",
      "- Flow Duration\n",
      "- Flow IAT Max\n",
      "- Flow IAT Mean\n",
      "- Flow Packets/s\n",
      "- Fwd IAT Mean\n",
      "- Fwd IAT Min\n",
      "- Fwd Packet Length Min\n",
      "- Init_Win_bytes_backward\n",
      "- Init_Win_bytes_forward\n",
      "- Min Packet Length\n",
      "- PSH Flag Count\n",
      "- Subflow Bwd Bytes\n",
      "- Subflow Fwd Bytes\n",
      "Train/Test shapes (selected features): (121278, 20) (51977, 20)\n"
     ]
    }
   ],
   "source": [
    "rf_estimator = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "n_features_to_select = min(20, X_train_base.shape[1])\n",
    "rfe = RFE(\n",
    "    estimator=rf_estimator,\n",
    "    n_features_to_select=n_features_to_select,\n",
    "    step=1\n",
    ")\n",
    "\n",
    "rfe.fit(X_train_base, y_train)\n",
    "\n",
    "selected_mask = rfe.support_\n",
    "selected_features = [f for f, m in zip(base_features, selected_mask) if m]\n",
    "\n",
    "print(f\"Selected TOP {n_features_to_select} features via RFE:\")\n",
    "for f in selected_features:\n",
    "    print(\"-\", f)\n",
    "\n",
    "# Reduce train/test to selected features only\n",
    "X_train_sel = X_train_base[:, selected_mask]\n",
    "X_test_sel = X_test_base[:, selected_mask]\n",
    "\n",
    "print(\"Train/Test shapes (selected features):\", X_train_sel.shape, X_test_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf032d",
   "metadata": {},
   "source": [
    "## 9. Train Final RandomForest on Selected Features\n",
    "\n",
    "We now train a **RandomForestClassifier** using only the 30 selected features and evaluate it on the test set:\n",
    "\n",
    "- Accuracy  \n",
    "- Precision, Recall, F1-score (classification report)  \n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f96063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RandomForest (Top 30 Features via RFE) Evaluation ===\n",
      "Accuracy: 0.9993\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      BENIGN       1.00      1.00      1.00     35888\n",
      "      ATTACK       1.00      1.00      1.00     16089\n",
      "\n",
      "    accuracy                           1.00     51977\n",
      "   macro avg       1.00      1.00      1.00     51977\n",
      "weighted avg       1.00      1.00      1.00     51977\n",
      "\n",
      "Confusion Matrix:\n",
      " [[35871    17]\n",
      " [   17 16072]]\n"
     ]
    }
   ],
   "source": [
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train_sel, y_train)\n",
    "\n",
    "y_pred = rf_final.predict(X_test_sel)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== RandomForest (Top 30 Features via RFE) Evaluation ===\")\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"BENIGN\", \"ATTACK\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f22e4b2",
   "metadata": {},
   "source": [
    "## 10. Forensic-Style Single Flow Prediction\n",
    "\n",
    "To simulate a **forensic analyst** inspecting a single network flow:\n",
    "\n",
    "1. We pick **one random row** from the cleaned dataset.  \n",
    "2. Extract the same base features and apply the RFE mask.  \n",
    "3. Use the trained RandomForest to predict whether this flow is **BENIGN** or **ATTACK**.  \n",
    "4. Show predicted probabilities as a form of confidence score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd649cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Flow Prediction (RF + RFE Top 30) ===\n",
      "Actual Label   : BENIGN\n",
      "Predicted Label: BENIGN\n",
      "Probabilities  -> BENIGN: 1.0000, ATTACK: 0.0000\n",
      "\n",
      "Sample row (all base features + label):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACK Flag Count</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Average Packet Size</th>\n",
       "      <th>Avg Fwd Segment Size</th>\n",
       "      <th>Bwd Header Length</th>\n",
       "      <th>Bwd IAT Max</th>\n",
       "      <th>Bwd IAT Mean</th>\n",
       "      <th>Bwd IAT Std</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Init_Win_bytes_backward</th>\n",
       "      <th>Init_Win_bytes_forward</th>\n",
       "      <th>Min Packet Length</th>\n",
       "      <th>PSH Flag Count</th>\n",
       "      <th>Subflow Bwd Bytes</th>\n",
       "      <th>Subflow Fwd Bytes</th>\n",
       "      <th>URG Flag Count</th>\n",
       "      <th>Attack_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1146427</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACK Flag Count  Active Max  Active Mean  Active Std  \\\n",
       "1146427               0           0          0.0         0.0   \n",
       "\n",
       "         Average Packet Size  Avg Fwd Segment Size  Bwd Header Length  \\\n",
       "1146427                 61.0                  36.0                 40   \n",
       "\n",
       "         Bwd IAT Max  Bwd IAT Mean  Bwd IAT Std  ...  Fwd Packet Length Min  \\\n",
       "1146427           48          48.0          0.0  ...                     36   \n",
       "\n",
       "         Idle Std  Init_Win_bytes_backward  Init_Win_bytes_forward  \\\n",
       "1146427       0.0                       -1                      -1   \n",
       "\n",
       "         Min Packet Length  PSH Flag Count  Subflow Bwd Bytes  \\\n",
       "1146427                 36               0                136   \n",
       "\n",
       "         Subflow Fwd Bytes  URG Flag Count  Attack_Binary  \n",
       "1146427                 72               0              0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample one random flow from the base dataframe\n",
    "sample = df_base.sample(1, random_state=None)\n",
    "\n",
    "# Extract base features and apply RFE mask\n",
    "sample_X_base = sample[base_features].values\n",
    "sample_X_sel = sample_X_base[:, selected_mask]\n",
    "\n",
    "# Predict\n",
    "sample_pred = rf_final.predict(sample_X_sel)[0]\n",
    "sample_proba = rf_final.predict_proba(sample_X_sel)[0]\n",
    "sample_actual = sample[\"Attack_Binary\"].iloc[0]\n",
    "\n",
    "print(\"=== Random Flow Prediction (RF + RFE Top 30) ===\")\n",
    "print(\"Actual Label   :\", \"ATTACK\" if sample_actual == 1 else \"BENIGN\")\n",
    "print(\"Predicted Label:\", \"ATTACK\" if sample_pred == 1 else \"BENIGN\")\n",
    "print(\"Probabilities  -> BENIGN: {:.4f}, ATTACK: {:.4f}\".format(sample_proba[0], sample_proba[1]))\n",
    "\n",
    "print(\"\\nSample row (all base features + label):\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b628c56-0e24-409c-81c1-73ba8930c92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
